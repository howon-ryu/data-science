number = 5,
repeats = 2,
returnResamp = 'final')
model2 <- train(mode ~.,
data = train,
method = 'svmLinear2',
metric = 'Accuracy',
trControl = trControl,
tuneGrid = tuneGrid
)
model2
model2$finalModel
model2$bestTune
#Model Evaluation
#Predict test set
pred <- predict(model2, test)
#pred <- factor(pred, levels = c("beach", "boat", "charter", "pier" ))
pred
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(pred, test$mode)
acc2 <- confusionMatrix(pred, test$mode)$overall['Accuracy']
acc2
modelLookup("svmRadial")
# optimization
trControl <- trainControl(method='repeatedcv', number = 10, repeats = 2)
model3 <- train(mode ~.,
data = train,
method = 'svmRadial',
metric = 'Accuracy',
trControl = trControl,
#tuneGrid=grid,
tuneLength = 5
)
# plot(model3)
# show final model
model3$finalModel
model3$bestTune
# Model Evaluation
# Predict testing set
pred <- predict(model3, newdata = test)
pred <- factor(pred, levels = c("beach", "boat", "charter", "pier" ))
pred
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(pred, test$mode)
acc3 <- confusionMatrix(pred, test$mode)$overall['Accuracy']
acc3
modelLookup("svmPoly")
# optimization
trControl <- trainControl(method='repeatedcv', number = 10, repeats = 2)
model4 <- train(mode ~.,
data = train,
method = 'svmPoly',
metric = 'Accuracy',
trControl = trControl,
#tuneGrid=grid,
tuneLength = 5
)
library(tidyverse)
library(rpart)
library(e1071)
library(caret)
# library(xlsx)
library(nnet)
set.seed(100) # Reproducibility setting
getModelInfo()
modelLookup("nnet")
# read the data
getwd()
# setwd("L:/?? ?????̺?/Rmarkdown")
fishing<- read.csv("Fishing.csv")
str(fishing)
# select variables
mode<- factor(data$mode, levels = c("beach", "boat", "charter", "pier" ))
head(data)
# select variables
mode<- factor(data$mode, levels = c("beach", "boat", "charter", "pier" ))
mode
price <- as.numeric(data$price)
catch<- as.numeric(data$catch)
income<- as.numeric(data$income)
ds<- data.frame(mode, price, catch, income)
str(ds)
head(ds)
# data preprocessing using caret::preProcess
# center and scale
preProcValues = preProcess(ds)
#The function preProcess estimates the required parameters for each operation and predict.preProcess is used to apply them to specific data sets. This function can also be interfaces when calling the train function.
ds <- predict(preProcValues, ds)
summary(ds)
ds
preProcValues
str(ds)
head(ds)
# split the data into tr and ts sets
set.seed(4) # random seed
indexes = createDataPartition(ds$mode, p = .6, list = F)
train = ds[indexes, ]
test = ds[-indexes, ]
train
test
fit = rpart(mode~.,
data = train
)
printcp(fit)
library(rattle)
fancyRpartPlot(fit)
pred = predict(fit, test, type = "class" )
print(data.frame(test, pred))
confusionMatrix(pred, test$mode)
# optimize model - rough
modelLookup("nnet")
# optimization
trControl=trainControl(method='repeatedcv', number = 10, repeats = 2)
model = train(mode ~.,
data = train,
method = 'nnet',
maxit = 500,
metric = 'Accuracy',
# preProcess = c('center', 'scale'), # data normalization
# We dont need to this, because the data is already scaled
trControl = trControl,
#tuneGrid=grid
tuneLength = 3
)
# show final model
model$finalModel
# check the convergence of the final model
model$finalModel$convergence
# Model Evaluation
# Predict testing set
pred <- predict(model$finalModel, newdata = test, type = "class")
pred <- factor(pred, levels = c("beach", "boat", "charter", "pier" ))
pred
print(data.frame(test$mode, pred))
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(pred, test$mode)
# for more optimization
# grid values
tuneGrid = expand.grid(size = 16:18, decay = 10 ** (-5:-3))
# for more optimization
# grid values
tuneGrid = expand.grid(size = 16:18, decay = 10 ** (-5:-3))
tuneGrid
trControl = trainControl(method = 'repeatedcv',
number = 5,
repeats = 2,
returnResamp = 'final')
model = train(mode ~.,
data = train,
method = 'nnet',
maxit = 1000,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
hc<- read.csv("hcvdat.csv")
hc
str(hc)
data <- hc
head(data)
head(data)
# setwd("L:/?? ?????̺?/Rmarkdown")
fishing<- read.csv("Fishing.csv")
str(fishing)
data <- fishing
head(data)
# select variables
mode<- factor(data$mode, levels = c("beach", "boat", "charter", "pier" ))
mode
head(mode)
head(ds)
hc<- read.csv("hcvdat.csv")
str(hc)
data <- hc
head(data)
# setwd("L:/?? ?????̺?/Rmarkdown")
fishing<- read.csv("Fishing.csv")
str(fishing)
data <- fishing
head(data)
str(fishing)
head(fishing)
hc<- read.csv("hcvdat.csv")
str(hc)
data <- hc
head(data)
mode<- factor(data$Category)
mode
mode<- factor(data$Category, levels = c("0", "0s", "1", "2","3" ))
mode
hc<- read.csv("hcvdat.csv")
str(hc)
data <- hc
head(data)
mode<- factor(data$Category, levels = c("0", "0s", "1", "2","3" ))
mode<- factor(data$Category, levels = c("0=Blood Donor", "0s=suspect Blood Donor ", "1=Hepatitis", "2=Fibrosis ","3=Cirrhosis" ))
mode
mode<- factor(data$Category, levels = c("0=Blood Donor", "0s=suspect Blood Donor", "1=Hepatitis", "2=Fibrosis","3=Cirrhosis" ))
mode
head(data)
cor(data[,])
cor(data)
cor(data[1,2])
cor(data[,-5])
str(hc)
library(tidyverse)
head(data)
data[,-1]
data[,-2]
library(tidyverse)
data[,-3]
data[,-1]
data<-data[,-1]
mode<- factor(data$Category, levels = c("0=Blood Donor", "0s=suspect Blood Donor", "1=Hepatitis", "2=Fibrosis","3=Cirrhosis" ))
mode
cor(data[,-5])
cor(data[,])
head(data)
cor(data[-1,])
pairs(data)
cor(data[,-c(1,3)])
head(data)
Sex <- as.numeric(data$Sex)
Category<- as.numeric(data$Category)
missmap(data)
library(Amelia)
missmap(data)
Sex <- as.numeric(data$Sex)
Category<- as.numeric(data$Category)
preProcValues = preProcess(data)
library(tidyverse)
library(rpart)
library(e1071)
library(caret)
# library(xlsx)
library(nnet)
library(Amelia)
library(kernlab) # svmLinear2
preProcValues = preProcess(data)
preProcValues
ds <- predict(preProcValues, data)
ds
summary(ds)
set.seed(4) # random seed
indexes = createDataPartition(ds$Category, p = .6, list = F)
train = ds[indexes, ]
test = ds[-indexes, ]
train
test
fit = rpart(Category~.,
data = train
)
printcp(fit)
library(rattle)
fancyRpartPlot(fit)
pred = predict(fit, test, type = "class" )
print(data.frame(test, pred))
confusionMatrix(pred, test$mode)
confusionMatrix(pred, test$mode)
confusionMatrix(pred, test$Category)
pred = predict(fit, test, type = "class" )
print(data.frame(test, pred))
confusionMatrix(pred, test$Category)
pred = as.factor(fit)
tmp
tmp <- data.frame(test, pred)
tmp
#tmp
#tmp$pred
acc <- sum(tmp$Category == tmp$pred) / nrow(tmp)
acc
# for more optimization
# grid values
# tunegrid=> 옵션값 특정
tuneGrid = expand.grid(size = 16:18, decay = 10 ** (-5:-3))
tuneGrid
trControl = trainControl(method = 'repeatedcv',
number = 5,
repeats = 2,
returnResamp = 'final')
model = train(mode ~.,
data = train,
method = 'nnet',
maxit = 1000,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
## nnet
tuneGrid = expand.grid(size = 1, decay = 5e-04)
tuneGrid
# 훈련에 지정할 훈련 파라미터 생성
# repeatedcv(교차 검증의 반복) , number : 교차검증 몇겹, repeats:반복 횟수
trControl = trainControl(method = 'repeatedcv',
number = 5,
repeats = 2,
returnResamp = 'final')
#maxit = 200 : 200반복해서 가장 좋은 모델 고르기
model = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
missmap(preProcValues)
missmap(data)
Sex <- as.numeric(data$Sex)
Category<- as.numeric(data$Category)
preProcValues = preProcess(data)
preProcValues
#maxit = 200 : 200반복해서 가장 좋은 모델 고르기
model = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
is.na(data$Category)
sum(is.na(data$Category))
#maxit = 200 : 200반복해서 가장 좋은 모델 고르기
model = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
#maxit = 200 : 200반복해서 가장 좋은 모델 고르기
train
sum(is.na(train$Category))
model = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
model = train(mode ~.,
data = train,
method = 'nnet',
maxit = 1000,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
missmap(train)
missmap(train)
missmap(test)
missmap(train)
str(hc)
sum(is.na(data))
data<-na.omit(data)
data
summary(data)
hc<- read.csv("hcvdat.csv")
str(hc)
data <- hc
summary(data)
data<-data[,-1]
mode<- factor(data$Category, levels = c("0=Blood Donor", "0s=suspect Blood Donor", "1=Hepatitis", "2=Fibrosis","3=Cirrhosis" ))
mode
head(data)
missmap(data)
sum(is.na(data))
data<-na.omit(data)
summary(data)
missmap(data)
Sex <- as.numeric(data$Sex)
Category<- as.numeric(data$Category)
preProcValues = preProcess(data)
preProcValues
missmap(preProcValues)
ds <- predict(preProcValues, data)
ds
summary(ds)
set.seed(4) # random seed
indexes = createDataPartition(ds$Category, p = .6, list = F)
train = ds[indexes, ]
test = ds[-indexes, ]
train
test
fit = rpart(Category~.,
data = train
)
printcp(fit)
fancyRpartPlot(fit)
pred = predict(fit, test, type = "class" )
pred = as.factor(fit)
print(data.frame(test, pred))
confusionMatrix(pred, test$Category)
tmp <- data.frame(test, pred)
tmp
#tmp
#tmp$pred
acc <- sum(tmp$Category == tmp$pred) / nrow(tmp)
acc
## nnet
tuneGrid = expand.grid(size = 1, decay = 5e-04)
tuneGrid
# 훈련에 지정할 훈련 파라미터 생성
# repeatedcv(교차 검증의 반복) , number : 교차검증 몇겹, repeats:반복 횟수
trControl = trainControl(method = 'repeatedcv',
number = 5,
repeats = 2,
returnResamp = 'final')
#maxit = 200 : 200반복해서 가장 좋은 모델 고르기
train
missmap(train)
missmap(test)
sum(is.na(train$Category))
model = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
model
#svm
model_svm <- train(mode ~.,
data = train,
method = 'svmLinear2',
metric = 'Accuracy',
tuneLength = 10,
trControl = trControl
)
#svm
model_svm <- train(Category ~.,
data = train,
method = 'svmLinear2',
metric = 'Accuracy',
tuneLength = 10,
trControl = trControl
)
model_svm
model_nnet
#nnet
model_nnet = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
model_nnet
model_svm
model2$finalModel
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(pred, test$mode)
acc4 <- confusionMatrix(pred, test$mode)$overall['Accuracy']
result <- tibble(Model = c('SVM Linear',
'SVM Linear w/choice of cost',
'SVM Radial',
'SVM POly',
'RPART'),
Accuracy = c(acc1,
acc2,
acc3,
acc4,
acc_rpart)
)
result %>% arrange(desc(Accuracy))
#svm
model_svm1 <- train(Category ~.,
data = train,
method = 'svmLinear2',
metric = 'Accuracy',
#tuneLength = 10,
trControl = trControl,
tuneGrid = tuneGrid
)
model_svm
model_svm1
#svm
model_svm1 <- train(Category ~.,
data = train,
method = 'svmLinear2',
metric = 'Accuracy',
#tuneLength = 10,
trControl = trControl,
tuneGrid = tuneGrid
)
## nnet
tuneGrid = expand.grid(size = 1, decay = 5e-04)
tuneGrid
#svm
model_svm1 <- train(Category ~.,
data = train,
method = 'svmLinear2',
metric = 'Accuracy',
#tuneLength = 10,
trControl = trControl,
tuneGrid = tuneGrid
)
#nnet
model_nnet = train(Category ~.,
data = train,
method = 'nnet',
maxit = 200,
metric = 'Accuracy',
trControl = trControl,
tuneGrid=tuneGrid
)
model_nnet
