---
title: "hw11"
output: html_document
date: '2022-05-12'
---


```{r}
# 라이브러리 포함
library(olsrr)
library(dplyr)
library(DAAG)
library(ggplot2)
library(mlbench)
library(tidyverse)
library(patchwork)

```


#2데이터 선택및 확인

*데이터 제목: Possum Regression(주머니 쥐 회귀)

*출처:https://www.kaggle.com/datasets/abrambeyer/openintro-possum?resource=download

*설명: 13가지의 예측변수를 바탕으로 주머니 쥐의 성별을 예측하는 데이터셋

*수집 목적: 

*예측변수
>site(뎃에 잡힌 주머니쥐의 장소 번호)외 12개

*목표 변수
>sex(성별)


```{r }
# 데이터 포함 및 데이터 확인
data <- read.csv('possum.csv')

summary(data)
head(data)
```


데이터 전처리
1~3열 제거 (case: 순서, site : 덧에 잡힌 장소 번호 , pop: 인구..? 장소...?)

명목형 변수인 sex의 m, f는 각각 1,2 로 변경

```{r}

d<-data[,-c(1,2,3)]
head(d)
df <- na.omit(d)  # 모든 변수에 결측치 없는 데이터 추출
df  
table(is.na(df))
summary(df)
head(df)
df$sex[df$sex == 'm'] <- as.numeric(1)
df$sex[df$sex == 'f'] <- as.numeric(2)
head(df)
str(df)

```

데이터 분포 확인


```{r }
p1<-ggplot(data=df) + geom_density(mapping=aes(x=age, colour = sex))
p2<-ggplot(data=df) + geom_density(mapping=aes(x=hdlngth, colour = sex))
p3<-ggplot(data=df) + geom_density(mapping=aes(x=skullw, colour = sex))
p4<-ggplot(data=df) + geom_density(mapping=aes(x=totlngth, colour = sex))
p5<-ggplot(data=df) + geom_density(mapping=aes(x=taill, colour = sex))
p6<-ggplot(data=df) + geom_density(mapping=aes(x=footlgth, colour = sex))
p7<-ggplot(data=df) + geom_density(mapping=aes(x=earconch, colour = sex))
p8<-ggplot(data=df) + geom_density(mapping=aes(x=eye, colour = sex))
p9<-ggplot(data=df) + geom_density(mapping=aes(x=chest, colour = sex))
p10<-ggplot(data=df) + geom_density(mapping=aes(x=belly, colour = sex))
```


```{r}
(p1+p2+p3)/(p4+p5+p6)/(p7+p8+p9+p10)
```


#3예측 모델 생성

Residuals:잔차를 의미합니다. 회귀식에 의해 추정된 값과 실제값(입력값)의 차이 입니다.
    최솟값/1사분위수/ 중앙값/ 3사분위수/ 최대값

     Min       1Q   Median       3Q      Max 
-0.68340 -0.36988 -0.09692  0.34943  1.07571
 
Coefficients:추정된 회귀식의 계수를 의미 합니다.
            추정된계수 / 표준오차 / t 값(점수) / p-value

             Estimate Std. Error t value  Pr(>|t|)  
(Intercept)  3.557151   1.899233   1.873   0.0659 .
age          0.043605   0.035435   1.231   0.2232  
hdlngth     -0.052560   0.026745  -1.965   0.0539 .
eye         -0.128666   0.056136  -2.292   0.0254 *

(Intercept)=> 절편


F-statistic: 2.067 on 10 and 61 DF,  p-value: 0.04125
=> 모형 전체의 유의성 판단 || p-value: 0.04125=> 유의
 
Residual standard error: 0.4629 on 61 degrees of freedom
=> 잔차의 표준오차 : 0.4629 || 자유도는 61(관측값에서 -1?)

t값: 각 독립변수의 유의성 판단을 위한 통계량

```{r}
set.seed(1000) 
idx<- caret::createDataPartition(df$sex, p=0.7)
df_train<-df[idx$Resample1,] # 트레인
df_test<-df[-idx$Resample1,] # 테스트
df_train
lmMod <- lm(sex ~ age + hdlngth + skullw + totlngth+taill+footlgth+earconch+eye+chest+belly, data=df_train)  # build the model
distPred <- predict(lmMod, df_test)
distPred
summary (lmMod)
```

양의 회귀계수와 음의 회귀계수가 혼재 되어 있음
p-value를 보았을때 회귀계수의 부호가 유의성을 설명하지는 않음


ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ



학습한 모델의 예측값와 테스트 데이터비교 => 정확성 


```{r}
actuals_preds <- data.frame(cbind(actuals=as.numeric(df_test$sex), predicteds=distPred))  # make actuals_predicteds dataframe.
actuals_preds
correlation_accuracy <- cor(actuals_preds)  
correlation_accuracy
head(actuals_preds)
```

최소최대 정확도와, 절대 백분율 편차 를 이용한 정확성 

: age를 수치화 해서 그런지 mape값이 너무 낮음

```{r}
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))  
min_max_accuracy #0.74 => 실제값과 예측값이 얼마나 근접한가
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)  
mape # 절대 백분율 편차 0.35 => 오차와 실제의 비율

```

#4예측 모델의 성능
rmse 오차 테스트(함수 rmse, cv rmse)

:cross vallidation 한쪽이 근사하게 낮으나 거의 비슷
그러나 rmse너무 높음

```{r}
rmse<-function(y1,y2){
  sqrt(mean((y1-y2)^2))
}

rmse_test_lm<-rmse(distPred,as.numeric(df_test$sex))
rmse_test_lm
cvResults <- suppressWarnings(
  CVlm(data = df, 
       form.lm=as.numeric(sex) ~ age + hdlngth + skullw + totlngth+taill+footlgth+earconch+eye+chest+belly, 
       m=10, 
       dots=FALSE, 
       seed=29, 
       legend.pos="topleft",  
       printit=FALSE, 
       main="Small symbols are predicted values while bigger ones are actuals."));  
# performs the CV

cv_ms<-attr(cvResults, 'ms')
cv_rms<-sqrt(cv_ms)
cv_rms
```

#5 설명 모델 생성과 설명모델 로서의 성능



A: 설명(종속변수와 독립변수간의 유의성 )하는것이 목적임

B: 


F-statistic: 2.174 on 10 and 90 DF,  p-value: 0.02645

 => 모형 전체의 유의성 판단 || p-value: 0.02645=> 유의

C: 

t-value값 기준 p-value 작은 순서

=>hdlngth>totlngth>eye>chest>belly>skullw>age>taill>footlgth>earconch

```{r}
model <- lm(as.numeric(sex) ~ age + hdlngth + skullw + totlngth+taill+footlgth+earconch+eye+chest+belly, data = df)
model
summary(model)
```

D: (선택1)stepwise-selection 진행

모델의 잔차와 측정 값


```{r}
ols_plot_resid_fit(model)
ols_plot_resid_fit_spread(model)
```



전방 선택 방식

eye>totlngth>hdlngth>chest 전방 선택시 순서로 중요한 변수임

```{r}
k <- ols_step_forward_p(model) # 
k 
plot(k)

```

후방 선택 방식


후방제거 시 earconch>footlgth>age>skullw>shest>taill 순서로 빠져야 함

```{r}

k <- ols_step_backward_aic(model) # for backward, ols_step_forward_aic()
k
plot(k)

```


두 방식을 모두 이용한 회귀

eye(addition)>totlngth(addition)>hdlngth(addition) 순서


```{r}
k <- ols_step_both_p(model) # for aic, ols_step_both_p()
k
plot(k)

```

독립변수의 개수별로 가장 적합한 모델을 나타낸다


adj-r-square와 cp와 aic를 고려 하였을때 4번 모델이 가장 좋아 보임임

```{r}
k <- ols_step_best_subset(model)
k
```



E:

설명력과은 무관하며 비례정도를 의미함

