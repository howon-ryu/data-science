windows()
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 2,
minbucket = 1 )
# prediction model
printcp(fit)
# plot the tree
windows()
plot(fit)
text(fit, cex = 0.9, xpd = TRUE)
readline('Enter to resume ')
windows()
fancyRpartPlot(fit)
readline('Enter to resume ')
windows()
rpart.plot(fit)
readline('Enter to resume ')
library(rpart.plot)
# Source code listing.
install rpart.plot
# Source code listing.
install.packages('rpart.plot')
library(rpart.plot)
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 2,
minbucket = 1 )
# prediction model
printcp(fit)
# plot the tree
windows()
plot(fit)
text(fit, cex = 0.9, xpd = TRUE)
readline('Enter to resume ')
windows()
fancyRpartPlot(fit)
readline('Enter to resume ')
windows()
rpart.plot(fit)
readline('Enter to resume ')
# Evaluate the performance of the prediction model
pred = predict(fit, test, type = "class", )
print(data.frame(test, pred))
confusionMatrix(test$Play, pred, positive = 'yes')
readline('Enter to resume ')
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
# cp = -1,
minsplit = 4,
minbucket = 2 )
# prediction model
printcp(fit)
# plot the tree
windows()
plot(fit)
text(fit, cex = 0.9, xpd = TRUE)
readline('Enter to resume ')
windows()
fancyRpartPlot(fit)
readline('Enter to resume ')
library(rpart)
library(e1071)
library(caret)
library(tidyverse)
library(rattle)
library(rpart.plot)
Golf_ds <- read.csv(file = "Golf-All.csv",
header = TRUE)
class(Golf_ds)
head(Golf_ds)
ds <- data.frame(Outlook = Golf_ds$Outlook,
Temperature = Golf_ds$Temperature,
Humidity = Golf_ds$Humidity,
Play = as.factor(Golf_ds$Play)
)
class(ds$Play)
# ds:Golf dataset,
# 28 obs. of 6 varibles,  remove ID variable.
indexes = createDataPartition(ds$Play, p = .6, list = F)
# tr set: 0.6
train = ds[indexes, ]
test = ds[-indexes, ]
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 2,
minbucket = 1 )
# prediction model
printcp(fit)
# ds:Golf dataset,
# 28 obs. of 6 varibles,  remove ID variable.
indexes = createDataPartition(ds$Play, p = .6, list = F)
str(indexes)
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 2,
minbucket = 1 )
# prediction model
printcp(fit)
# plot the tree
windows()
plot(fit)
text(fit, cex = 0.9, xpd = TRUE)
readline('Enter to resume ')
windows()
fancyRpartPlot(fit)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rattle")
library(rpart.plot)
library(rattle)
library(RColorBrewer)
fancyRpartPlot(fit)
readline('Enter to resume ')
windows()
rpart.plot(fit)
readline('Enter to resume ')
# Evaluate the performance of the prediction model
pred = predict(fit, test, type = "class", )
print(data.frame(test, pred))
confusionMatrix(test$Play, pred, positive = 'yes')
# prediction model
printcp(fit)
library(rpart)
library(e1071)
library(caret)
library(tidyverse)
library(rattle)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
Golf_ds <- read.csv(file = "Golf-All.csv",
header = TRUE)
class(Golf_ds)
head(Golf_ds)
ds <- data.frame(Outlook = Golf_ds$Outlook,
Temperature = Golf_ds$Temperature,
Humidity = Golf_ds$Humidity,
Play = as.factor(Golf_ds$Play)
)
class(ds$Play)
# ds:Golf dataset,
# 28 obs. of 6 varibles,  remove ID variable.
indexes = createDataPartition(ds$Play, p = .6, list = F)
str(indexes)
# tr set: 0.6
train = ds[indexes, ]
test = ds[-indexes, ]
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 2,
minbucket = 1 )
# prediction model
printcp(fit)
str(fit)
# plot the tree
windows()
plot(fit)
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 1,
minbucket = 1 )
# prediction model
printcp(fit)
str(fit)
# plot the tree
windows()
plot(fit)
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
cp = -1,
minsplit = 2,
minbucket = 1 )
windows()
fancyRpartPlot(fit)
# Evaluate the performance of the prediction model
pred = predict(fit, test, type = "class", )
print(data.frame(test, pred))
confusionMatrix(test$Play, pred, positive = 'yes')
readline('Enter to resume ')
readline('Enter to resume ')
c
# Fit a prediction model
# rpart parameters
# minsplit:
# minbucket:
# cp:
fit <- rpart(Play~.,
data = ds,
# cp = -1,
minsplit = 4,
minbucket = 2 )
# prediction model
printcp(fit)
# plot the tree
windows()
plot(fit)
text(fit, cex = 0.9, xpd = TRUE)
readline('Enter to resume ')
dev.off() # close window
windows()
fancyRpartPlot(fit)
readline('Enter to resume ')
windows()
rpart.plot(fit)
readline('Enter to resume ')
# Evaluate the performance of the prediction model
pred = predict(fit, test, type = "class", )
print(data.frame(test, pred))
confusionMatrix(test$Play, pred, positive = 'yes')
confusionMatrix(test$Play, pred, positive = 'yes')
# ?뜲?씠?꽣 遺덈윭?삤湲?
ob <- read.csv("ObesityDataSet.csv", header = T)
# 紐⑺몴蹂?닔 4媛吏濡? 蹂?솚 ?썑 ?긽愿怨꾩닔 怨꾩궛?쓣 ?쐞?빐 ?닔移섑삎?쑝濡? 蹂寃쎄꼍
ob$NObeyesdad[ob$NObeyesdad == 'Insufficient_Weight'] <- 1
ob$NObeyesdad[ob$NObeyesdad == 'Normal_Weight'] <- 2
ob$NObeyesdad[ob$NObeyesdad == 'Overweight_Level_I' | ob$NObeyesdad == 'Overweight_Level_II'] <- 3
ob$NObeyesdad[ob$NObeyesdad == 'Obesity_Type_I' | ob$NObeyesdad == 'Obesity_Type_II' | ob$NObeyesdad == 'Obesity_Type_III'] <- 4
ob$NObeyesdad <- as.numeric(ob$NObeyesdad)
# ?뜲?씠?꽣 ?쟾泥섎━ : factor?삎?쑝濡? 蹂寃쏀븷嫄? 蹂寃?
ob1 <- data.frame(Gender = as.factor(ob$Gender),
Age = ob$Age,
Height = ob$Height,
Weight = ob$Weight,
family_history = as.factor(ob$family_history_with_overweight),
FAVC = as.factor(ob$FAVC),
FCVC = ob$FCVC,
NCP = ob$NCP,
CAEC = factor(ob$CAEC, levels = c('no', 'Sometimes', 'Frequently', 'Always')),
SMOKE = as.factor(ob$SMOKE),
CH2O = ob$CH2O,
SCC = as.factor(ob$SCC),
FAF = ob$FAF,
TUE = ob$TUE,
CALC = factor(ob$CALC, levels = c('no', 'Sometimes', 'Frequently', 'Always')),
MTRANS = factor(ob$MTRANS, levels = c('Walking', 'Bike', 'Public_Transportation', 'Motorbike', 'Automobile')),
NObeyesdad = factor(ob$NObeyesdad, levels = c(1, 2, 3, 4)))
# 紐⑺몴蹂?닔 鍮꾩쑉 洹몃옒?봽 洹몃━?뒗 寃껊뱾
library(ggplot2)
freqob <- xtabs(~NObeyesdad, data = ob1)
proportions(freqob) *100
ggplot(ob1, aes(x = NObeyesdad)) + geom_bar(fill = c(1, 2, 3, 4))
freqob
pie(freqob)
source("C:/Users/qorgh2akfl/Desktop/데사기/4주차/hw4_ver2.R")
library(rpart)
library(e1071)
library(caret)
library(tidyverse)
library(rattle)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
data <- read.csv(file = "C:/Users/qorgh2akfl/Desktop/데사기/4주차/health.csv", header = TRUE)
str(data)
class(data)
head(data)
summary(data)
indexes = createDataPartition(data$NObeyesdad, p = .8, list = F)
str(indexes)
summary(indexes)
train = data[indexes, ]
test = data[-indexes, ]
train
summary(train)
summary(test)
fit <- rpart(NObeyesdad~.,
data = train,
cp = -1,
minsplit = 2,
minbucket = 75 )
printcp(fit)
str(fit)
summary(fit)
windows()
plot(fit)
text(fit, cex = 1, xpd = TRUE)
readline('Enter to resume ')
plotcp(check)
#xerror(교차 에러?)가 최소일때의 CP값
check$cptable[which.min(check$cptable[,"xerror"]),"CP"]
# cp값이 0~0.01 사이 값들 나온다.
# 나온 cp값으로 가지치기 진행 (여기부터는 안써도 될듯, 그냥 나온 값으로 cp적당히 정하기)
ptree<-prune(check, cp= check$cptable[which.min(check$cptable[,"xerror"]),"CP"])
ptree
# cp값이 0~0.01 사이 값들 나온다.
# 나온 cp값으로 가지치기 진행 (여기부터는 안써도 될듯, 그냥 나온 값으로 cp적당히 정하기)
ptree<-prune(check, cp= check$cptable[which.min(check$cptable[,"xerror"]),"CP"])
library(rpart)
# 나는 최적을 minsplit = 10, minbucket = 3, maxdepth = 10 으로 정함
#method는 각각 목적이 다름, 우리는 분류기 때문에 class 사용
#cp 최적값 찾기
check <- make_tree_r(sdf, minsplit = 10, minbucket = 3, maxdepth = 10)
#return 푼 버전
make_tree_r <- function(data, cp_ = -1, ...){
indexes = createDataPartition(data$NObeyesdad, p = .6, list = F)
train = data[indexes, ]
test = data[-indexes, ]
fit <- rpart(NObeyesdad~.,
data = train,
cp = cp_, method = "class", ...)
pred = predict(fit, test, type = "class", )
tmp <- data.frame(test, pred)
acc <- sum(tmp$NObeyesdad == tmp$pred) / nrow(tmp)
#print(confusionMatrix(test$NObeyesdad, pred, positive = '4'))
print(acc * 100)
return(fit)
}
# 열 골라서 추출하기
# dplyr의 select함수 이용
# 첫번째에 원본 데이터프레임, 그 다음부터 추출할 열 이름들
# 무조건 넣기로한 3가지 속성과 목표변수 추출
library(dplyr)
sdf <- select(ob1, Weight, family_history, FAVC, NObeyesdad)
# 데이터 불러오기
ob <- read.csv("ObesityDataSet.csv", header = T)
# 목표변수 4가지로 변환 후 상관계수 계산을 위해 수치형으로 변경경
ob$NObeyesdad[ob$NObeyesdad == 'Insufficient_Weight'] <- 1
ob$NObeyesdad[ob$NObeyesdad == 'Normal_Weight'] <- 2
ob$NObeyesdad[ob$NObeyesdad == 'Overweight_Level_I' | ob$NObeyesdad == 'Overweight_Level_II'] <- 3
ob$NObeyesdad[ob$NObeyesdad == 'Obesity_Type_I' | ob$NObeyesdad == 'Obesity_Type_II' | ob$NObeyesdad == 'Obesity_Type_III'] <- 4
ob$NObeyesdad <- as.numeric(ob$NObeyesdad)
# 데이터 전처리 : factor형으로 변경할거 변경
ob1 <- data.frame(Gender = as.factor(ob$Gender),
Age = ob$Age,
Height = ob$Height,
Weight = ob$Weight,
family_history = as.factor(ob$family_history_with_overweight),
FAVC = as.factor(ob$FAVC),
FCVC = ob$FCVC,
NCP = ob$NCP,
CAEC = factor(ob$CAEC, levels = c('no', 'Sometimes', 'Frequently', 'Always')),
SMOKE = as.factor(ob$SMOKE),
CH2O = ob$CH2O,
SCC = as.factor(ob$SCC),
FAF = ob$FAF,
TUE = ob$TUE,
CALC = factor(ob$CALC, levels = c('no', 'Sometimes', 'Frequently', 'Always')),
MTRANS = factor(ob$MTRANS, levels = c('Walking', 'Bike', 'Public_Transportation', 'Motorbike', 'Automobile')),
NObeyesdad = factor(ob$NObeyesdad, levels = c(1, 2, 3, 4)))
# 목표변수 비율 그래프 그리는 것들
library(ggplot2)
freqob <- xtabs(~NObeyesdad, data = ob1)
proportions(freqob) *100
ggplot(ob1, aes(x = NObeyesdad)) + geom_bar(fill = c(1, 2, 3, 4))
freqob
# 데이터를 기반으로 트리를 만들어서 정확도를 확인하는 함수
# data = 데이터프레임, cp나 뒤에 다른 인자들은 rpart에 들어감
# 만약 만들어서 밖에서도 쓰고 싶으면 return # 지우고 사용
# 혼동행렬 보고 싶으면 print 앞에 # 지우면 나올거임
library(caret)
make_tree <- function(data, cp_ = -1, ...){
indexes = createDataPartition(data$NObeyesdad, p = .6, list = F)
train = data[indexes, ]
test = data[-indexes, ]
fit <- rpart(NObeyesdad~.,
data = train,
cp = cp_, method = "class", ...)
pred = predict(fit, test, type = "class", )
tmp <- data.frame(test, pred)
acc <- sum(tmp$NObeyesdad == tmp$pred) / nrow(tmp)
#print(confusionMatrix(test$NObeyesdad, pred, positive = '4'))
print(acc * 100)
#return(fit)
}
#return 푼 버전
make_tree_r <- function(data, cp_ = -1, ...){
indexes = createDataPartition(data$NObeyesdad, p = .6, list = F)
train = data[indexes, ]
test = data[-indexes, ]
fit <- rpart(NObeyesdad~.,
data = train,
cp = cp_, method = "class", ...)
pred = predict(fit, test, type = "class", )
tmp <- data.frame(test, pred)
acc <- sum(tmp$NObeyesdad == tmp$pred) / nrow(tmp)
#print(confusionMatrix(test$NObeyesdad, pred, positive = '4'))
print(acc * 100)
return(fit)
}
# rpart의 인자들을 다르게 해보자
for(i in 1:20){ #최대 깊이를 1~20
make_tree(ob1, maxdepth = i)
}
for(i in seq(1, 100, 5)){ #1, 6, 11, ..., 96
make_tree(ob1, minsplit = i)
}
for(i in 1:10){ # 1~10
make_tree(ob1, minbucket = i)
}
for(i in seq(0.01, 0.5, 0.05)){ #0.01, 0.015, 0.02, ..., 0.5
make_tree(ob1, cp_ = i)
}
sdf <- select(ob1, Weight, family_history, FAVC, NObeyesdad)
sdf
# 나는 최적을 minsplit = 10, minbucket = 3, maxdepth = 10 으로 정함
#method는 각각 목적이 다름, 우리는 분류기 때문에 class 사용
#cp 최적값 찾기
check <- make_tree_r(sdf, minsplit = 10, minbucket = 3, maxdepth = 10)
plotcp(check)
#xerror(교차 에러?)가 최소일때의 CP값
check$cptable[which.min(check$cptable[,"xerror"]),"CP"]
# cp값이 0~0.01 사이 값들 나온다.
# 나온 cp값으로 가지치기 진행 (여기부터는 안써도 될듯, 그냥 나온 값으로 cp적당히 정하기)
ptree<-prune(check, cp= check$cptable[which.min(check$cptable[,"xerror"]),"CP"])
ptree
rpartpred<-predict(ptree, test, type='class')
ptree
ptree
rpartpred<-predict(ptree, train, type='class')
rpartpred<-predict(ptree, 1, type='class')
rpartpred<-predict(ptree, ob1, type='class')
confusionMatrix(rpartpred, test$NObeyesdad)
rpartpred<-predict(ptree, test, type='class')
sdf <- select(ob1, family_history, FAVC, NObeyesdad)
sdf
# 나는 최적을 minsplit = 10, minbucket = 3, maxdepth = 10 으로 정함
#method는 각각 목적이 다름, 우리는 분류기 때문에 class 사용
#cp 최적값 찾기
check <- make_tree_r(sdf, minsplit = 10, minbucket = 3, maxdepth = 10)
plotcp(check)
sdf <- select(ob1, family_history, FAVC, NObeyesdad)
sdf
# 나는 최적을 minsplit = 10, minbucket = 3, maxdepth = 10 으로 정함
#method는 각각 목적이 다름, 우리는 분류기 때문에 class 사용
#cp 최적값 찾기
check <- make_tree_r(sdf, minsplit = 10, minbucket = 3, maxdepth = 10)
plotcp(check)
plotcp(check)
#xerror(교차 에러?)가 최소일때의 CP값
check$cptable[which.min(check$cptable[,"xerror"]),"CP"]
# cp값이 0~0.01 사이 값들 나온다.
# 나온 cp값으로 가지치기 진행 (여기부터는 안써도 될듯, 그냥 나온 값으로 cp적당히 정하기)
ptree<-prune(check, cp= check$cptable[which.min(check$cptable[,"xerror"]),"CP"])
ptree
sdf <- select(ob1, Weight, family_history, FAVC, NObeyesdad)
sdf
# 나는 최적을 minsplit = 10, minbucket = 3, maxdepth = 10 으로 정함
#method는 각각 목적이 다름, 우리는 분류기 때문에 class 사용
#cp 최적값 찾기
check <- make_tree_r(sdf, minsplit = 10, minbucket = 3, maxdepth = 10)
plotcp(check)
#xerror(교차 에러?)가 최소일때의 CP값
check$cptable[which.min(check$cptable[,"xerror"]),"CP"]
# cp값이 0~0.01 사이 값들 나온다.
# 나온 cp값으로 가지치기 진행 (여기부터는 안써도 될듯, 그냥 나온 값으로 cp적당히 정하기)
ptree<-prune(check, cp= check$cptable[which.min(check$cptable[,"xerror"]),"CP"])
ptree
rpartpred<-predict(ptree, test, type='class')
sdf <- select(ob1, Weight, family_history, FAVC, NObeyesdad)
sdf
# 나는 최적을 minsplit = 10, minbucket = 3, maxdepth = 10 으로 정함
#method는 각각 목적이 다름, 우리는 분류기 때문에 class 사용
#cp 최적값 찾기
check <- make_tree_r(sdf, minsplit = 10, minbucket = 3, maxdepth = 10)
plotcp(check)
#xerror(교차 에러?)가 최소일때의 CP값
check$cptable[which.min(check$cptable[,"xerror"]),"CP"]
# cp값이 0~0.01 사이 값들 나온다.
# 나온 cp값으로 가지치기 진행 (여기부터는 안써도 될듯, 그냥 나온 값으로 cp적당히 정하기)
ptree<-prune(check, cp= check$cptable[which.min(check$cptable[,"xerror"]),"CP"])
ptree
rpartpred<-predict(ptree, test, type='class')
confusionMatrix(rpartpred, test$NObeyesdad)
